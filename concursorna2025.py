# -*- coding: utf-8 -*-
"""ConcursoRNA2025

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YRwLrcVlCvzMD6Je1yLpCVpUHYRPCx1Y
"""

#descargamos esto
!pip install mlflow
!pip install optuna
#Importamos la libreria a utilizar
import os
from getpass import getpass
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import mlflow
import mlflow.keras
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks, optimizers, regularizers
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score, roc_auc_score
import optuna
import json
import time
#cargamos el archivo csv de la base de datos usando lo siguiente
from google.colab import files
import pandas as pd
from sklearn.model_selection import train_test_split

#este lo usamos para subir el archivo
uploaded = files.upload()

# si el nombre exacto es "global_house_purchase_dataset.csv"
CSV_PATH = "/content/global_house_purchase_dataset.csv"

#esto lee el archivo csv
df = pd.read_csv(CSV_PATH)

#usamos esto para que se verifiquen las primeras filas
print("Dataset cargado correctamente. Primeras filas:")
display(df.head())
#se muestran
print(f"\nNúmero de filas: {len(df)}")
print(f"Columnas: {list(df.columns)}")
#nuestra columna objetivo es esta
TARGET_COLUMN = "decision"

# separamos variables
X = df.drop(columns=[TARGET_COLUMN])
y = df[TARGET_COLUMN]

# se eliminan las filas
X = X.dropna().reset_index(drop=True)
y = y[X.index]
print("Shape luego de dropna:", X.shape)

# X: usamos esto para convertir variables categóricas simples usando dummies
X = pd.get_dummies(X, drop_first=True)
print("X shape después de dummies:", X.shape)


#hacemos tambien un escalado
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

#hacemos la division de los datos datos
# separamos 20 % para test lo demas se guarda  en trainval
X_trainval, X_test, y_trainval, y_test = train_test_split(
    X_scaled, y, test_size=0.20, random_state=42, stratify=y if len(np.unique(y))>1 else None)

# ahora separamos train  70 % total y val 10 % total del trainval
# nota consideramos que  trainval es 80% del total
# para val la proporcion es la siguiente  = 10/80 = 0.125
X_train, X_val, y_train, y_val = train_test_split(
    X_trainval, y_trainval, test_size=0.125, random_state=42, stratify=y_trainval if len(np.unique(y))>1 else None)


print(f"\nTamaño de entrenamiento: {len(X_train)} ({len(X_train)/len(X)*100:.1f}%)")
print(f"Tamaño de validación:   {len(X_val)} ({len(X_val)/len(X)*100:.1f}%)")
print(f"Tamaño de prueba:       {len(X_test)} ({len(X_test)/len(X)*100:.1f}%)")


print("\n Datos listos para entrenamiento con Optuna y MLflow.")

# hacemos esto para las dimenciones de entrada
input_shape = X_train.shape[1]
num_classes = len(np.unique(y_train))
print("Input dim:", input_shape, "Num clases:", num_classes)

# usamos esto para la claificacion binaria
is_binary = (num_classes == 2)


#usamos esto para registrar todo con dagshub y mlflow
REPO_OWNER = "javimesa16"
REPO_NAME  = "Concurso"
USER_NAME  = "javimesa16"


if REPO_OWNER and REPO_NAME:
    tracking_uri = f'https://dagshub.com/{REPO_OWNER}/{REPO_NAME}.mlflow'
    print("Usando MLflow tracking URI:", tracking_uri)
    os.environ['MLFLOW_TRACKING_USERNAME'] = USER_NAME
    os.environ['MLFLOW_TRACKING_PASSWORD'] = getpass('Enter your DAGsHub access token or password: ')
    mlflow.set_tracking_uri(tracking_uri)
else:
    print("No se proporcionó REPO_OWNER/REPO_NAME. Usando MLflow local (archivo).")


# nombre del experimento en mlflow
EXPERIMENT_NAME = "HousePurchase_Optuna_Experiment"

# los hiperpatametros con optuna con 20 pruebas
N_TRIALS = 20

# entrenamiento final con los mejores hiperparametros que encuentre optuna
FINAL_EPOCHS = 50 #epocas
BATCH_SIZE = 64

# guardamos el archivo csv en esta ruta
CSV_PATH = "/content/global_house_purchase_dataset.csv"
BEST_MODEL_PATH = "best_model_final.h5" #aqui se guardara el mejor modelo
#hacemos que cada 5 epocas se generen las graficas necesarias automaticamente
#en dagshub


class MLflowEpochLogger(Callback):
    def __init__(self, run_id=None, log_every_n_epochs=1, plot_every_n_epochs=5):
        super().__init__()
        self.log_every_n_epochs = log_every_n_epochs
        self.plot_every_n_epochs = plot_every_n_epochs
        self.history = {'loss':[], 'val_loss':[], 'accuracy':[], 'val_accuracy':[], 'test_loss':[], 'test_accuracy':[]}
        self.run_id = run_id

    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        # se actualiza el historial
        for k in ['loss','val_loss','accuracy','val_accuracy']:
            if k in logs:
                self.history[k].append(float(logs[k]))

        # evaluamos test en cada epoca para tener test_loss y test_accuracy
        test_loss, test_acc = self.model.evaluate(X_test, y_test, verbose=0)
        self.history['test_loss'].append(float(test_loss))
        self.history['test_accuracy'].append(float(test_acc))
        logs['test_loss'] = float(test_loss)
        logs['test_accuracy'] = float(test_acc)

        # aqui se hace esto para registrar métricas en mlflow por época
        if (epoch + 1) % self.log_every_n_epochs == 0:
            for k, v in logs.items():
                try:
                    mlflow.log_metric(k, float(v), step=epoch)
                except Exception as e:
                    print("Warning mlflow.log_metric:", e)

        # cada 5 epocas sube las graficas
        if (epoch + 1) % self.plot_every_n_epochs == 0:
            try:
                # graficas del loss vs epochs
                fig, ax = plt.subplots()
                ax.plot(range(1, len(self.history['loss'])+1), self.history['loss'], label='train_loss')
                ax.plot(range(1, len(self.history['val_loss'])+1), self.history['val_loss'], label='val_loss')
                ax.plot(range(1, len(self.history['test_loss'])+1), self.history['test_loss'], label='test_loss')
                ax.set_xlabel('epoch'); ax.set_ylabel('loss'); ax.legend()
                loss_img = f'loss_epoch_{epoch+1}.png'
                fig.savefig(loss_img)
                plt.close(fig)
                mlflow.log_artifact(loss_img, artifact_path="plots")
                os.remove(loss_img)

                # grafica del accuracy vs epochs
                fig, ax = plt.subplots()
                ax.plot(range(1, len(self.history['accuracy'])+1), self.history['accuracy'], label='train_acc')
                ax.plot(range(1, len(self.history['val_accuracy'])+1), self.history['val_accuracy'], label='val_acc')
                ax.plot(range(1, len(self.history['test_accuracy'])+1), self.history['test_accuracy'], label='test_acc')
                ax.set_xlabel('epoch'); ax.set_ylabel('accuracy'); ax.legend()
                acc_img = f'acc_epoch_{epoch+1}.png'
                fig.savefig(acc_img)
                plt.close(fig)
                mlflow.log_artifact(acc_img, artifact_path="plots")
                os.remove(acc_img)

            except Exception as e:
                print("Warning al crear/logear plots:", e)

#crea/selecciona el experimento con el nombre dado
try:
    mlflow.set_experiment(EXPERIMENT_NAME)
    print(f"Experimento MLflow establecido: {EXPERIMENT_NAME}")
except Exception as e:
    print("Warning al set_experiment:", e)

#definimos el modelo con optuna y sus valores
def create_model_from_trial(trial):
    model = models.Sequential()
    model.add(layers.Input(shape=(input_shape,)))

    #el numero de capas
    n_layers = trial.suggest_int("n_layers", 1, 4)

    #el dropout
    dropout_rate = trial.suggest_float("dropout", 0.0, 0.5)

    for i in range(n_layers):
        n_units = trial.suggest_int(f"n_units_l{i}", 16, 512, log=True)
        # se agrega l2 como opcion de regularizador
        l2 = trial.suggest_float(f"l2_l{i}", 0.0, 1e-2)
        model.add(layers.Dense(n_units, activation='relu', kernel_regularizer=regularizers.l2(l2)))
        if dropout_rate > 0:
            model.add(layers.Dropout(dropout_rate))

    # si es binario se usa la sigmoide si no el softmax
    if is_binary:
        model.add(layers.Dense(1, activation='sigmoid'))
    else:
        model.add(layers.Dense(num_classes, activation='softmax'))

    # para el learning rate y el optimizador
    lr = trial.suggest_float("lr", 1e-5, 1e-1, log=True)
    optimizer_name = trial.suggest_categorical("optimizer", ["adam", "sgd", "rmsprop"])
    if optimizer_name == "adam":
        optimizer = optimizers.Adam(learning_rate=lr)
    elif optimizer_name == "sgd":
        optimizer = optimizers.SGD(learning_rate=lr)
    else:
        optimizer = optimizers.RMSprop(learning_rate=lr)

    # compilamos  con toda la informacion
    if is_binary:
        loss = "binary_crossentropy"
        metrics = ["accuracy"]
    else:
        loss = "sparse_categorical_crossentropy"
        metrics = ["accuracy"]

    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)
    return model


#ahora enviamos esto a mlflow
def objective(trial):

    try:
        mlflow.start_run(nested=True)
    except Exception:
        mlflow.start_run()

    # logemos los hiperparametros que encontro o sugirio optina
    trial_params = {}
    model = create_model_from_trial(trial)
    trial_params = trial.params
    try:
        mlflow.log_params(trial_params)
    except Exception as e:
        print("Warning log_params:", e)

    # usamos EarlyStopping 8 epocas , Checkpoint guardar y MLflowEpochLogger
    #para subir la informacion
    run_id = mlflow.active_run().info.run_id
    checkpoint_path = f"best_model_trial_{run_id}.h5"
    checkpoint_cb = ModelCheckpoint(checkpoint_path, monitor='val_loss', verbose=0, save_best_only=True, mode='min')
    earlystop_cb = EarlyStopping(monitor='val_loss', mode='min', patience=8, restore_best_weights=True, verbose=0)
    mlflow_logger_cb = MLflowEpochLogger(log_every_n_epochs=1, plot_every_n_epochs=5)

    #graficas
    history = model.fit(
        X_train, y_train,
        validation_data=(X_val, y_val),
        epochs=20,
        batch_size=BATCH_SIZE,
        callbacks=[checkpoint_cb, earlystop_cb, mlflow_logger_cb],
        verbose=0
    )


    val_loss, val_acc = model.evaluate(X_val, y_val, verbose=0)
    # guardamos el modelo (el mejor encontrado por checkpoint)
    try:
        if os.path.exists(checkpoint_path):
            mlflow.log_artifact(checkpoint_path, artifact_path="models")
            # se registra el modelo
            mlflow.keras.log_model(tf.keras.models.load_model(checkpoint_path), artifact_path="keras_model")
    except Exception as e:
        print("Warning al logear artifact de checkpoint:", e)

    # subimos el historial usando JSON
    try:
        hist_json = json.dumps(history.history)
        with open("history.json", "w") as f:
            f.write(hist_json)
        mlflow.log_artifact("history.json", artifact_path="history")
        os.remove("history.json")
    except Exception as e:
        print("Warning al logear history:", e)

    # aqui se termina
    mlflow.end_run()


    return float(val_loss)

#ejecutamos el estudio optuna
study = optuna.create_study(direction="minimize")
print("Iniciando optimización Optuna con", N_TRIALS, "trials...")
study.optimize(objective, n_trials=N_TRIALS)
print("Optimización completa. Mejor valor:", study.best_value)
print("Mejores hiperparámetros:", study.best_params)

#el entrenamiento final se hara con los mejores parametros
best_params = study.best_params

#  aqui se construye el modelo final usando los mejores parámetros
def build_model_from_best_params(params):
    model = models.Sequential()
    model.add(layers.Input(shape=(input_shape,)))
    n_layers = params.get("n_layers", 1)
    dropout_rate = params.get("dropout", 0.0)
    for i in range(n_layers):
        n_units = params.get(f"n_units_l{i}", 32)
        l2 = params.get(f"l2_l{i}", 0.0)
        model.add(layers.Dense(int(n_units), activation='relu', kernel_regularizer=regularizers.l2(float(l2))))
        if dropout_rate and dropout_rate > 0:
            model.add(layers.Dropout(float(dropout_rate)))
    if is_binary:
        model.add(layers.Dense(1, activation='sigmoid'))
    else:
        model.add(layers.Dense(num_classes, activation='softmax'))

    lr = params.get("lr", 1e-3)
    optimizer_name = params.get("optimizer", "adam")
    if optimizer_name == "adam":
        optimizer = optimizers.Adam(learning_rate=float(lr))
    elif optimizer_name == "sgd":
        optimizer = optimizers.SGD(learning_rate=float(lr))
    else:
        optimizer = optimizers.RMSprop(learning_rate=float(lr))

    if is_binary:
        loss = "binary_crossentropy"; metrics = ["accuracy"]
    else:
        loss = "sparse_categorical_crossentropy"; metrics = ["accuracy"]

    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)
    return model

final_model = build_model_from_best_params(best_params)
final_model.summary()

# callbacks para el entrenamiento final
checkpoint_cb = ModelCheckpoint(BEST_MODEL_PATH, monitor='val_loss', verbose=1, save_best_only=True, mode='min')
earlystop_cb = EarlyStopping(monitor='val_loss', mode='min', patience=10, restore_best_weights=True, verbose=1)
mlflow_logger_cb = MLflowEpochLogger(log_every_n_epochs=1, plot_every_n_epochs=5)

# se inicia la carga a mlflow el entrenamiento final
try:
    mlflow.start_run(run_name="final_training")
except Exception:
    mlflow.start_run()

# se  registrar parámetros finales
try:
    mlflow.log_params(best_params)
except Exception as e:
    print("Warning al logear params final:", e)

# entrenamiento final
history = final_model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=FINAL_EPOCHS,
    batch_size=BATCH_SIZE,
    callbacks=[checkpoint_cb, earlystop_cb, mlflow_logger_cb],
    verbose=1
)

# se evalual el mejor modelo en test
if os.path.exists(BEST_MODEL_PATH):
    final_model = tf.keras.models.load_model(BEST_MODEL_PATH)

test_results = final_model.evaluate(X_test, y_test, verbose=1)
print("Test results (loss, accuracy):", test_results)

# se hacen las predicciones
y_pred_prob = final_model.predict(X_test)
if is_binary:
    y_pred = (y_pred_prob.ravel() >= 0.5).astype(int)
else:
    y_pred = np.argmax(y_pred_prob, axis=1)

print("Accuracy (test):", accuracy_score(y_test, y_pred))
try:
    print("Classification report (test):\n", classification_report(y_test, y_pred))
except Exception as e:
    print("Warning al generar classification_report:", e)

# enviamos el modelo final a mlflow
try:
    mlflow.keras.log_model(final_model, artifact_path="final_keras_model")
    mlflow.log_artifact(BEST_MODEL_PATH, artifact_path="models")
except Exception as e:
    print("Warning al logear modelo final:", e)

# tambien sus metricas
try:
    mlflow.log_metric("test_loss", float(test_results[0]))
    mlflow.log_metric("test_accuracy", float(test_results[1]))
except Exception as e:
    print("Warning al logear métricas finales:", e)

mlflow.end_run()

print(" completado. Mejor modelo guardado en:", BEST_MODEL_PATH)

!pip install optuna

!pip install mlflow